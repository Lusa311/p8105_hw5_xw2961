---
title: "p8105_hw5_xw2961"
output: github_document
date: "`Nov 15`"
---

# Loading packages
```{r}
 library(tidyverse)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
```

# Problem 2
```{r}
# Set Parameters
n <- 30  # Sample size
sigma <- 5  # Standard deviation
mu_values <- c(0, 1, 2, 3, 4, 5, 6)  # True mean values
num_simulations <- 5000  # Number of iterations
alpha <- 0.05  # Significance level

# Create Simulator Function
sim_func <- function(mu, sample_size, population_std) {
  # Simulate data
  data <- rnorm(sample_size, mean = mu, sd = population_std)
  
  # Perform t-test and tidy results
  t_test <- broom::tidy(t.test(data, mu = 0)) %>%
    select(estimate, p.value)
  
  return(t_test)
}

# Perform Simulations
sim_df <- expand_grid(
  mu = mu_values,
  iteration = 1:num_simulations
) %>%
  mutate(result = map(mu, ~ sim_func(mu = .x, sample_size = n, population_std = sigma))) %>%
  unnest(result)  # Combine results into a single data frame

# Group by mu and calculate power
power_results <- sim_df %>%
  group_by(mu) %>%
  summarize(
    power = mean(p.value < alpha)  # Proportion of null hypothesis rejections
  )

# Plot Power vs True Mean
library(ggplot2)

ggplot(power_results, aes(x = mu, y = power)) +
  geom_line(color = "blue") +
  geom_point(size = 2) +
  labs(
    title = "Power vs True Mean (mu)",
    x = "True Value of mu",
    y = "Power"
  ) +
  theme_minimal()

```
The plot shows a positive association between effect size (\( \mu \)) and statistical power, where power increases as the effect size grows. For small effect sizes, the power is low, indicating a lower likelihood of detecting a true effect. As the effect size increases, the power rises rapidly, reflecting a higher probability of correctly rejecting the null hypothesis. Beyond a certain threshold (e.g., \( \mu \geq 5 \)), the power plateaus near 1, indicating near certainty in detecting a true effect. This demonstrates that larger effect sizes make it easier to distinguish between the null and alternative hypotheses, emphasizing the importance of sufficient effect sizes for well-powered studies.
```{r}
# Calculate averages
average_results <- sim_df %>%
  group_by(mu) %>%
  summarize(
    avg_mu_hat = mean(estimate),  # Overall average of sample means
    avg_rejected_mu_hat = mean(estimate[p.value < alpha], na.rm = TRUE)  # Average sample mean for null rejected
  )

# Plot overall average and null rejected average
ggplot(average_results, aes(x = mu)) +
  geom_line(aes(y = avg_mu_hat, color = "Overall Average")) +
  geom_point(aes(y = avg_mu_hat, color = "Overall Average")) +
  geom_line(aes(y = avg_rejected_mu_hat, color = "Null Rejected Average")) +
  geom_point(aes(y = avg_rejected_mu_hat, color = "Null Rejected Average")) +
  labs(
    title = "Average Estimate vs True Value of Mu",
    x = "True Value of Mu",
    y = "Average Estimate",
    color = "Legend"
  ) +
  theme_minimal()
```
The sample average of $\hat{\mu}$ from tests where the null hypothesis is rejected does not match the true value of (\( \mu \)), especially when (\( \mu \)) is close to the null hypothesis value (0).
This occurs because tests that reject the null are biased toward samples with larger deviations from 0, inflating the mean estimate. This selection bias is most evident when (\( \mu \)) is small since only extreme values of mu_hat produce significant results. 
As (\( \mu \)) increases, the test's power improves, reducing the impact of selection bias, and the rejected-sample estimates converge more closely to the true (\( \mu \)). 
This pattern illustrates how bias diminishes with increasing effect size.


# Problem 3
```{r}
# Loading the dataset
data_url <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicides_data <- read_csv(data_url)
```
The raw data originates from The Washington Post's homicide dataset and provides comprehensive information on individual homicide cases from 50 major U.S. cities. It encompasses a total of 52,179 observations distributed across 12 variables. Each row corresponds to a unique case and includes detailed attributes such as the date of the incident, victim demographics (e.g., name, age, race, sex, and ethnicity), the case's disposition (e.g., "Closed by arrest" or "Open/No arrest"), and geographical details like city, state, latitude, and longitude. This dataset spans the past decade and provides a valuable resource for analyzing criminal homicides in these cities.
```{r}
# Create the city_state variable and summarize within the city
homicides_df <- homicides_data %>%
  mutate(city_state = paste(city, state, sep = ", ")) %>% 
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),  # Total number of homicides
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))  # Unsolved homicides
  )

# Estimate the proportion of homicides for Baltimore
baltimore_df <- homicides_df %>%
  filter(city_state == "Baltimore, MD") %>%  # Filter for Baltimore, MD
  summarize(
    total_homicides = total_homicides,  # Already exists in dataset
    unsolved_homicides = unsolved_homicides  # Already exists in dataset
  ) %>%
  mutate(
    prop_test = list(
      prop.test(x = unsolved_homicides, n = total_homicides, correct = FALSE, conf.level = 0.95)  # Perform prop.test
    )
  ) %>%
  mutate(tidy_output = map(prop_test, broom::tidy)) %>%  # Tidy the prop.test output
  unnest(tidy_output) %>%  # Unnest the tidy result
  select(estimate, conf.low, conf.high)  # Select the proportion and confidence intervals

print(baltimore_df)

# prop-test for each of the city
all_df <- homicides_df %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = sum(total_homicides),
    unsolved_homicides = sum(unsolved_homicides)
  ) %>%
  mutate(
    prop_test = map2(
      unsolved_homicides,
      total_homicides,
      ~ prop.test(x = .x, n = .y, correct = FALSE)  # Ensure continuity correction is consistent
    )
  ) %>%
  mutate(tidy_output = map(prop_test, broom::tidy)) %>%
  unnest(tidy_output) %>%
  select(city_state, estimate, conf.low, conf.high)


print (all_df)


# Plot
plot_data <- all_df %>%
  arrange(estimate) %>%  # Sort by the proportion
  mutate(city_state = factor(city_state, levels = city_state))  # Keep sorted order

ggplot(plot_data, aes(x = estimate, y = city_state)) +
  geom_point(size = 1) +  # Reduce dot size
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +  # Add error bars
  scale_x_continuous(
    breaks = seq(0, 1, by = 0.1),  # Set x-axis ticks at 0.1 intervals
    limits = c(0, 1)  # Restrict range to 0-1
  ) +
  theme_minimal() +  # Use a minimal theme with grid lines
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "Proportion of Unsolved Homicides",
    y = "City"
  ) +
  theme(
    panel.grid.major = element_line(color = "gray80", size = 0.5),  # Add major grid lines
    panel.grid.minor = element_blank(),  # Remove minor grid lines
    axis.text.y = element_text(size = 7),  # Reduce city label size
    axis.text.x = element_text(size = 10),
    axis.title = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  )


plot_data

```


